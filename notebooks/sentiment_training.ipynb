import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.preprocessing.text import Tokenizer
import pickle

df = pd.read_csv("file.csv")
df.head()
texts = df['tweets'].astype(str)
labels = df['labels'].astype(str)
le = LabelEncoder()
y = le.fit_transform(labels)
tokenizer = Tokenizer(num_words=1000)
tokenizer.fit_on_texts(texts)
X = tokenizer.texts_to_matrix(texts, mode='binary')
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
num_classes = len(np.unique(y))  # Három osztály: bad, neutral, good

model = Sequential([
    Dense(64, activation='relu', input_shape=(X.shape[1],)),
    Dense(num_classes, activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))
import os
os.makedirs("models", exist_ok=True)
model.save("models/sentiment_model.h5")

with open("models/tokenizer.pkl", "wb") as f:
    pickle.dump(tokenizer, f)

